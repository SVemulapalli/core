{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1377617ec4c1781f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:34:42.834100Z",
     "start_time": "2024-06-07T21:34:42.824051Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# import os\n",
    "#\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"...\"\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = \"...\"\n",
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "\n",
    "load_dotenv(Path(\"../.env.test\"), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "808bae4c98be5c94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:34:43.397025Z",
     "start_time": "2024-06-07T21:34:43.394067Z"
    }
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c49d5afd7ed94163",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:34:45.597153Z",
     "start_time": "2024-06-07T21:34:45.183731Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from zenbase.types import LMRequest, deflm\n",
    "from langsmith import traceable\n",
    "from langsmith.schemas import Run, Example\n",
    "from langsmith.wrappers import wrap_openai\n",
    "from openai import OpenAI\n",
    "\n",
    "openai = wrap_openai(OpenAI())\n",
    "\n",
    "# Define your LLM function\n",
    "@traceable\n",
    "def openai_json_response(inputs: dict) -> dict:\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an expert math solver. Your answer must be just the number with no separators, and nothing else. Follow the format of the examples. Think step by step. Respond with a JSON object with a key of 'answer'.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": json.dumps(inputs)}\n",
    "    ]\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "\n",
    "    return json.loads(response.choices[0].message.content)\n",
    "\n",
    "# Define your Langsmith evaluator\n",
    "def score_answer(run: Run, example: Example):\n",
    "    match (answer := run.outputs[\"answer\"]):\n",
    "        case int():\n",
    "            output = str(answer).strip()\n",
    "        case str():\n",
    "            output = answer.split(\"#### \")[-1].strip()\n",
    "    target = example.outputs[\"answer\"].split(\"#### \")[-1].strip()\n",
    "    return {\n",
    "        \"key\": \"correctness\",\n",
    "        \"score\": int(output == target),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "269ce9c328f8e5e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:34:50.592052Z",
     "start_time": "2024-06-07T21:34:46.755696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'respectful-picture-95' at:\n",
      "https://smith.langchain.com/o/b0308fb6-cdef-5df3-affa-b8dba287e3ed/datasets/1b7abb1a-8922-4eba-b0b6-b617241d8794/compare?selectedSessions=31355c7b-8a3d-406f-a493-9fbd75bcab49\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e32fe251c2cb4e4a841799b483e741d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ExperimentResults respectful-picture-95>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate using LangSmith\n",
    "from langsmith import Client, evaluate\n",
    "\n",
    "langsmith = Client()\n",
    "evalset = list(langsmith.list_examples(dataset_name=\"gsm8k-test-examples\"))\n",
    "\n",
    "evaluate_kwargs = dict(\n",
    "    data=evalset,\n",
    "    evaluators=[score_answer],\n",
    "    client=langsmith,\n",
    "    max_concurrency=2,\n",
    ")\n",
    "\n",
    "evaluate(openai_json_response, **evaluate_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9592f3913f694364",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:35:09.830906Z",
     "start_time": "2024-06-07T21:35:09.824879Z"
    }
   },
   "outputs": [],
   "source": [
    "# Wrap your existing chain with @deflm and take in a `LMRequest` object\n",
    "# An LMRequest has the inputs for your chain and has a `zenbase` attribute.\n",
    "# This `zenbase` attribute includes the fields that Zenbase optimises.\n",
    "\n",
    "# LMRequest.inputs => LM function inputs\n",
    "# LMRequest.zenbase => optimized LLM params\n",
    "\n",
    "@deflm\n",
    "@traceable\n",
    "def openai_json_response(request: LMRequest) -> dict:\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an expert math solver. Your answer must be just the number with no separators, and nothing else. Follow the format of the examples. Think step by step. Respond with a JSON object.\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    for demo in request.zenbase.task_demos:\n",
    "        messages += [\n",
    "            {\"role\": \"user\", \"content\": json.dumps(demo.inputs)},\n",
    "            {\"role\": \"assistant\", \"content\": json.dumps(demo.outputs)},\n",
    "        ]\n",
    "    messages.append({\"role\": \"user\", \"content\": json.dumps(request.inputs)})\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "\n",
    "    return json.loads(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c996174108b0981",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:35:37.205056Z",
     "start_time": "2024-06-07T21:35:22.266388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'zenbase-self-enabling-bottom-line-09778677' at:\n",
      "https://smith.langchain.com/o/b0308fb6-cdef-5df3-affa-b8dba287e3ed/datasets/1b7abb1a-8922-4eba-b0b6-b617241d8794/compare?selectedSessions=4935af04-7b3d-42cc-8705-43db56c2264b\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bbdbe7db32446e1bdd2b21136a5b57f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'zenbase-configurable-5thgeneration-11d6767f' at:\n",
      "https://smith.langchain.com/o/b0308fb6-cdef-5df3-affa-b8dba287e3ed/datasets/1b7abb1a-8922-4eba-b0b6-b617241d8794/compare?selectedSessions=f00ff465-bd92-45a3-a62e-2624a84260aa\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a0fc30d3f00483aa59ad92a556f21a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from zenbase.helpers.langchain import ZenLangSmith\n",
    "from zenbase.optim.metric.labeled_few_shot import LabeledFewShot\n",
    "\n",
    "demoset = ZenLangSmith.examples_to_demos(\n",
    "    langsmith.list_examples(dataset_name=\"gsm8k-golden-demos\")\n",
    ")\n",
    "optimizer = LabeledFewShot(demoset=demoset, shots=3)\n",
    "\n",
    "best_fn, candidates = optimizer.perform(\n",
    "    # Pass deflm decorated function\n",
    "    openai_json_response,\n",
    "    # Exactly the same as what you are passing to your evaluate function\n",
    "    evaluator=ZenLangSmith.metric_evaluator(**evaluate_kwargs),\n",
    "    samples=2,\n",
    "    rounds=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6e5476084d83fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:35:41.601645Z",
     "start_time": "2024-06-07T21:35:39.374294Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'I have 30% + Mo has 24.5% = 54.5% shares assigned.\\nTherefore, there are 100% - 54.5% = <<100-54.5=45.5>>45.5% shares unassigned.\\nThere are 10M * 45.5% = <<10*45.5/100=4550000>>4550000 unassigned shares.\\n#### 4550000'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now you can use your zenbase fn\n",
    "best_fn({\"question\": \"If I have 30% of shares, and Mo has 24.5% of shares, how many of our 10M shares are unassigned?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280bbbc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LMDemo(inputs={'question': 'James writes a 3-page letter to 2 different friends twice a week.  How many pages does he write a year?'}, outputs={'answer': 'He writes each friend 3*2=<<3*2=6>>6 pages a week\\nSo he writes 6*2=<<6*2=12>>12 pages every week\\nThat means he writes 12*52=<<12*52=624>>624 pages a year\\n#### 624'}),\n",
       " LMDemo(inputs={'question': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?'}, outputs={'answer': 'Natalia sold 48/2 = <<48/2=24>>24 clips in May.\\nNatalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\\n#### 72'}),\n",
       " LMDemo(inputs={'question': 'Betty is saving money for a new wallet which costs $100. Betty has only half of the money she needs. Her parents decided to give her $15 for that purpose, and her grandparents twice as much as her parents. How much more money does Betty need to buy the wallet?'}, outputs={'answer': \"In the beginning, Betty has only 100 / 2 = $<<100/2=50>>50.\\nBetty's grandparents gave her 15 * 2 = $<<15*2=30>>30.\\nThis means, Betty needs 100 - 50 - 30 - 15 = $<<100-50-30-15=5>>5 more.\\n#### 5\"}))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_fn.zenbase.task_demos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622d32eb538487a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:35:46.575798Z",
     "start_time": "2024-06-07T21:35:46.116757Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': '4'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also save the zenbase params for re-use\n",
    "import pickle\n",
    "\n",
    "pickled_zenbase = pickle.dumps(best_fn.zenbase)\n",
    "openai_json_response.zenbase = pickle.loads(pickled_zenbase)\n",
    "\n",
    "openai_json_response({\"question\": \"What is 2 + 2?\"}) # uses the best few-shot demos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00806fd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
