{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import the Zenbase Library"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "297ac2e185a1ec3b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install_package(package):\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Failed to install {package}: {e}\")\n",
    "        raise\n",
    "\n",
    "def install_packages(packages):\n",
    "    for package in packages:\n",
    "        install_package(package)\n",
    "\n",
    "try:\n",
    "    # Check if running in Google Colab\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Install the zenbase package if running in Google Colab\n",
    "    # install_package('zenbase')\n",
    "    # Install the zenbse package from a GitHub branch if running in Google Colab\n",
    "    install_package('git+https://github.com/zenbase-ai/lib.git@main#egg=zenbase&subdirectory=py')\n",
    "\n",
    "    # List of other packages to install in Google Colab\n",
    "    additional_packages = [\n",
    "        'python-dotenv',\n",
    "        'langsmith[vcr]',\n",
    "        'openai',\n",
    "        'langchain',\n",
    "        'langchain_openai'\n",
    "    ]\n",
    "    \n",
    "    # Install additional packages\n",
    "    install_packages(additional_packages)\n",
    "\n",
    "# Now import the zenbase library\n",
    "try:\n",
    "    import zenbase\n",
    "except ImportError as e:\n",
    "    print(\"Failed to import zenbase: \", e)\n",
    "    raise"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90cbce6f536bbc1d",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Configure the Environment"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a7763c93879d642f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1377617ec4c1781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# import os\n",
    "#\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"...\"\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = \"...\"\n",
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "\n",
    "load_dotenv(Path(\"../../.env.test\"), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808bae4c98be5c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Initial Setup"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bbf3e9e3a82a3db7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langsmith.wrappers import wrap_openai\n",
    "from openai import OpenAI\n",
    "\n",
    "openai = wrap_openai(OpenAI())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29d4415d36107124",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Now, you probably already have some LLM code."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a324fc452bc8197"
  },
  {
   "cell_type": "markdown",
   "source": [
    "It could use the OpenAI SDK, LangChain, or anything really. But it looks something like this:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de5f4afdde31cbd3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49d5afd7ed94163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langsmith import traceable\n",
    "from langsmith.schemas import Run, Example\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "@traceable\n",
    "def solver(inputs):\n",
    "    messages = [\n",
    "        (\"system\", \"\"\"You are an expert math solver. Solve the given problem using the provided plan and operations.\n",
    "        Return only the final numerical answer, without any additional text or explanation.\"\"\"),\n",
    "        (\"user\", \"Question: {question}\"),\n",
    "        (\"user\", \"Plan: {plan}\"),\n",
    "        (\"user\", \"Mathematical Operation: {operation}\"),\n",
    "        (\"user\", \"Provide the final numerical answer:\")\n",
    "    ]\n",
    "\n",
    "    chain = ChatPromptTemplate.from_messages(messages) | ChatOpenAI(model=\"gpt-3.5-turbo\") | StrOutputParser()\n",
    "\n",
    "    plan = planner_chain(inputs)\n",
    "    operation = operation_finder({\"plan\": plan[\"plan\"], \"question\": inputs[\"question\"]})\n",
    "    \n",
    "    inputs_to_answer = {\n",
    "        \"question\": inputs[\"question\"],\n",
    "        \"plan\": plan[\"plan\"],\n",
    "        \"operation\": operation[\"operation\"],\n",
    "    }\n",
    "    answer = chain.invoke(inputs_to_answer)\n",
    "    return {\"answer\": answer}\n",
    "\n",
    "@traceable\n",
    "def planner_chain(inputs):\n",
    "    messages = [\n",
    "        (\"system\", \"\"\"You are an expert math solver. Create a step-by-step plan to solve the given problem.\n",
    "        Be clear and concise in your steps.\"\"\"),\n",
    "        (\"user\", \"Problem: {question}\\n\\nProvide a step-by-step plan to solve this problem:\")\n",
    "    ]\n",
    "\n",
    "    chain = ChatPromptTemplate.from_messages(messages) | ChatOpenAI(model=\"gpt-3.5-turbo\") | StrOutputParser()\n",
    "    plan = chain.invoke(inputs)\n",
    "    return {\"plan\": plan}\n",
    "\n",
    "@traceable\n",
    "def operation_finder(inputs):\n",
    "    messages = [\n",
    "        (\"system\", \"\"\"You are an expert math solver. Identify the overall mathematical operation needed to solve the problem \n",
    "        based on the given plan. Use simple operations like addition, subtraction, multiplication, and division.\"\"\"),\n",
    "        (\"user\", \"Question: {question}\"),\n",
    "        (\"user\", \"Plan: {plan}\"),\n",
    "        (\"user\", \"Identify the primary mathematical operation needed:\")\n",
    "    ]\n",
    "\n",
    "    chain = ChatPromptTemplate.from_messages(messages) | ChatOpenAI(model=\"gpt-3.5-turbo\") | StrOutputParser()\n",
    "    operation = chain.invoke(inputs)\n",
    "    return {\"operation\": operation}"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## And let's say you have an eval function like this"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9509dc99a65652c6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def score_answer(run: Run, example: Example):\n",
    "    output = run.outputs[\"answer\"].split(\"#### \")[-1]\n",
    "    target = example.outputs[\"answer\"].split(\"#### \")[-1]\n",
    "    return {\n",
    "        \"key\": \"correctness\",\n",
    "        \"score\": int(output == target),\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "309b233df7ba4912",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Then you're probably evaluating like this"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "532947c7de246b4f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269ce9c328f8e5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate using LangSmith\n",
    "from langsmith import Client, evaluate\n",
    "\n",
    "langsmith = Client()\n",
    "evalset = list(langsmith.list_examples(dataset_name=\"GSM8K_test_set_langsmith_dataset_2j24kEFx8T718mqwRblcoNK3S0L\"))\n",
    "\n",
    "evaluate_kwargs = dict(\n",
    "    data=evalset,\n",
    "    evaluators=[score_answer],\n",
    "    client=langsmith,\n",
    "    max_concurrency=2,\n",
    ")\n",
    "\n",
    "evaluate(solver, **evaluate_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    " # Now, how can we optimize this score?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "463a61739518337f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## First, initialize the Zenbase ZenbaseTracer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "627f4479a42d3c9c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from zenbase.core.managers import ZenbaseTracer\n",
    "zenbase_tracer = ZenbaseTracer()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7edd4903633743a",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hook up Zenbase to your functions\n",
    "\n",
    "1. Use the `zenbase_tracer` decorator.\n",
    "2. Change function inputs to request\n",
    "3. Use request's `zenbase.task_demos` to get the few-shot examples for the task and add them however you would like into your prompt.\n",
    "4. If you need to use just a few examples, you can use `request.zenbase.task_demos[:2]` to get the first two examples."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd9ca6b5c562771f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9592f3913f694364",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenbase.types import LMRequest\n",
    "\n",
    "\n",
    "@zenbase_tracer  # it is 1\n",
    "@traceable\n",
    "def solver(request: LMRequest):  # it is 2\n",
    "    messages = [\n",
    "        (\"system\", \"\"\"You are an expert math solver. Solve the given problem using the provided plan and operations.\n",
    "        Return only the final numerical answer, without any additional text or explanation.\"\"\"),\n",
    "    ]\n",
    "\n",
    "    for demo in request.zenbase.task_demos: # it is 3\n",
    "        messages += [\n",
    "            (\"user\", f'Example Question: {demo.inputs[\"question\"]}'),\n",
    "            (\"assistant\", f'Example Answer: {demo.outputs[\"answer\"]}'),\n",
    "        ] # it is 4\n",
    "    \n",
    "    messages.extend([\n",
    "        (\"user\", \"Question: {question}\"),\n",
    "        (\"user\", \"Plan: {plan}\"),\n",
    "        (\"user\", \"Mathematical Operation: {operation}\"),\n",
    "        (\"user\", \"Provide the final numerical answer:\")\n",
    "    ])\n",
    "\n",
    "    chain = ChatPromptTemplate.from_messages(messages) | ChatOpenAI(model=\"gpt-3.5-turbo\") | StrOutputParser()\n",
    "\n",
    "    plan = planner_chain(request.inputs)\n",
    "    operation = operation_finder({\"plan\": plan[\"plan\"], \"question\": request.inputs[\"question\"]})\n",
    "\n",
    "    inputs_to_answer = {\n",
    "        \"question\": request.inputs[\"question\"],\n",
    "        \"plan\": plan[\"plan\"],\n",
    "        \"operation\": operation[\"operation\"],\n",
    "    }\n",
    "    answer = chain.invoke(inputs_to_answer)\n",
    "    return {\"answer\": answer}\n",
    "\n",
    "\n",
    "@zenbase_tracer  # it is 1\n",
    "@traceable\n",
    "def planner_chain(request: LMRequest):  # it is 2\n",
    "    messages = [\n",
    "        (\"system\", \"\"\"You are an expert math solver. Create a step-by-step plan to solve the given problem.\n",
    "        Be clear and concise in your steps.\"\"\"),\n",
    "        (\"user\", \"Problem: {question}\\n\\nProvide a step-by-step plan to solve this problem:\")\n",
    "    ]\n",
    "\n",
    "    if request.zenbase.task_demos:  # it is 3\n",
    "        for demo in request.zenbase.task_demos[:2]:  # it is 4\n",
    "            messages += [\n",
    "                (\"user\", demo.inputs[\"question\"]),\n",
    "                (\"assistant\", demo.outputs[\"plan\"]),\n",
    "            ]\n",
    "\n",
    "    chain = ChatPromptTemplate.from_messages(messages) | ChatOpenAI(model=\"gpt-3.5-turbo\") | StrOutputParser()\n",
    "    plan = chain.invoke(request.inputs)\n",
    "    return {\"plan\": plan}\n",
    "\n",
    "\n",
    "@zenbase_tracer  # it is 1\n",
    "@traceable\n",
    "def operation_finder(request: LMRequest):  # it is 2\n",
    "    messages = [\n",
    "        (\"system\", \"\"\"You are an expert math solver. Identify the overall mathematical operation needed to solve the problem \n",
    "        based on the given plan. Use simple operations like addition, subtraction, multiplication, and division.\"\"\"),\n",
    "        (\"user\", \"Question: {question}\"),\n",
    "        (\"user\", \"Plan: {plan}\"),\n",
    "        (\"user\", \"Identify the primary mathematical operation needed:\")\n",
    "    ]\n",
    "\n",
    "    if request.zenbase.task_demos:  # it is 3 \n",
    "        for demo in request.zenbase.task_demos[:2]:  # it is 4\n",
    "            messages += [\n",
    "                (\"user\", demo.inputs[\"question\"]),\n",
    "                (\"user\", demo.inputs[\"plan\"]),\n",
    "                (\"assistant\", demo.outputs[\"operation\"]),\n",
    "            ]\n",
    "\n",
    "    chain = ChatPromptTemplate.from_messages(messages) | ChatOpenAI(model=\"gpt-3.5-turbo\") | StrOutputParser()\n",
    "    operation = chain.invoke(request.inputs)\n",
    "    return {\"operation\": operation}"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Now we can optimize!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6be90130ae43e7e6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set up your optimizer:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be3d4c7df5d5fe5e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from zenbase.adaptors.langchain import ZenLangSmith\n",
    "from zenbase.optim.metric.bootstrap_few_shot import BootstrapFewShot\n",
    "\n",
    "# Define your Langsmith and helper\n",
    "langsmith = Client()\n",
    "zen_langsmith_adaptor = ZenLangSmith(client=langsmith)\n",
    "\n",
    "TRAIN_SET = \"GSM8K_train_set_langsmith_dataset_2j24jtX6pr5OFyi9IRlj2Pk29NX\"\n",
    "TEST_SET = \"GSM8K_test_set_langsmith_dataset_2j24kEFx8T718mqwRblcoNK3S0L\"\n",
    "VALIDATION_SET = \"GSM8K_validation_set_langsmith_dataset_2j24kCxc6WhYDe27hEcnhUEHPmE\"\n",
    "SHOTS = 2\n",
    "SAMPLES = 2\n",
    "\n",
    "train_set = zen_langsmith_adaptor.fetch_dataset(dataset_name=TRAIN_SET)\n",
    "test_set = zen_langsmith_adaptor.fetch_dataset(dataset_name=TEST_SET)\n",
    "validation_set = zen_langsmith_adaptor.fetch_dataset(dataset_name=VALIDATION_SET)\n",
    "\n",
    "evaluator_kwargs = dict(\n",
    "    evaluators=[score_answer],\n",
    "    client=langsmith,\n",
    "    max_concurrency=1,\n",
    ")\n",
    "\n",
    "bootstrap_few_shot = BootstrapFewShot(\n",
    "    shots=SHOTS,\n",
    "    training_set=train_set,\n",
    "    test_set=test_set,\n",
    "    validation_set=validation_set,\n",
    "    evaluator_kwargs=evaluator_kwargs,\n",
    "    zen_adaptor=zen_langsmith_adaptor,\n",
    ")\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c7008ff5c73da1c",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Do the optimization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa5e591a161f3318"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "best_fn, candidates = bootstrap_few_shot.perform(\n",
    "    solver,\n",
    "    samples=SAMPLES,\n",
    "    rounds=1,\n",
    "    trace_manager=zenbase_tracer,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ce98837b3cd1f20",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Introspect evaluation improvement\n",
    "\n",
    "You can see in this example that the best function has improved the evaluation score by 50%."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc72f474aeafcdc1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "bootstrap_few_shot.base_evaluation.evals"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "106ee1d1be4088a3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "bootstrap_few_shot.best_evaluation.evals"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "148eba8ce5614f76",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Use your optimized function"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42ead38d1179c979"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "zenbase_tracer.all_traces = {}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f3128cd993847a92"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Now you can use your zenbase fn\n",
    "best_fn({\"question\": \"If I have 30% of shares, and Mo has 24.5% of shares, how many of our 10M shares are unassigned?\"})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "673698a3ac4d9706",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Introspect function traces"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fbad50bcd672f3fe"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "function_traces = [v for k, v in zenbase_tracer.all_traces.items()][0][\"optimized\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a89e03362a776bc",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Check the optimized parameters for solver\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e190e5e7bb623be"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280bbbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(function_traces[\"solver\"][\"args\"][\"request\"].zenbase.task_demos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Check the optimized parameters for operation_finder\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dbebcd1af07c36c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(function_traces[\"operation_finder\"][\"args\"][\"request\"].zenbase.task_demos)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc02d3eb7132f76d",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Check the optimized parameters for planner_chain\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e64c9d27f8cf4fe8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(function_traces[\"planner_chain\"][\"args\"][\"request\"].zenbase.task_demos)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ac8df87e61c41d0",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## How to save the function and load it later"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6882afc26f54b354"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save the optimized function args to a file"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f38fd21f76b3cbb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "bootstrap_few_shot.save_optimizer_args(\"bootstrap_few_shot_args.zenbase\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee823dd2db26e925",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load the optimized function args with the function"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec286af05ba833d8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622d32eb538487a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_function = bootstrap_few_shot.load_optimizer_and_function(\"bootstrap_few_shot_args.zenbase\", solver, zenbase_tracer)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Use the loaded function and make sure it loaded the demos."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa5be6fa9f6d11f4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d795c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenbase_tracer.all_traces = {}\n",
    "optimized_function({\"question\": \"If I have 30% of shares, and Mo has 24.5% of shares, how many of our 10M shares are unassigned?\"})\n",
    "function_traces = [v for k, v in zenbase_tracer.all_traces.items()][0][\"optimized\"]\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(function_traces[\"solver\"][\"args\"][\"request\"].zenbase.task_demos)\n",
    "pprint(function_traces[\"planner_chain\"][\"args\"][\"request\"].zenbase.task_demos)\n",
    "pprint(function_traces[\"operation_finder\"][\"args\"][\"request\"].zenbase.task_demos)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
